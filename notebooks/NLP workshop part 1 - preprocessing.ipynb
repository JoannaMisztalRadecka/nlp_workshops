{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Przetwarzanie-tekstu---przygotowanie-i-analiza-eksploracyjna\" data-toc-modified-id=\"Przetwarzanie-tekstu---przygotowanie-i-analiza-eksploracyjna-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Przetwarzanie tekstu - przygotowanie i analiza eksploracyjna</a></div><div class=\"lev2 toc-item\"><a href=\"#Importy,-czyli-co-będzie-potrzebne\" data-toc-modified-id=\"Importy,-czyli-co-będzie-potrzebne-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Importy, czyli co będzie potrzebne</a></div><div class=\"lev2 toc-item\"><a href=\"#Słowniczek\" data-toc-modified-id=\"Słowniczek-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Słowniczek</a></div><div class=\"lev2 toc-item\"><a href=\"#Analiza-eksploracyjna\" data-toc-modified-id=\"Analiza-eksploracyjna-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Analiza eksploracyjna</a></div><div class=\"lev4 toc-item\"><a href=\"#Czytanie-danych---artykułów\" data-toc-modified-id=\"Czytanie-danych---artykułów-1301\"><span class=\"toc-item-num\">1.3.0.1&nbsp;&nbsp;</span>Czytanie danych - artykułów</a></div><div class=\"lev3 toc-item\"><a href=\"#Skąd-pochodzą-teksty?\" data-toc-modified-id=\"Skąd-pochodzą-teksty?-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Skąd pochodzą teksty?</a></div><div class=\"lev3 toc-item\"><a href=\"#Jaki-jest-rozkład-czasu-publikacji?\" data-toc-modified-id=\"Jaki-jest-rozkład-czasu-publikacji?-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Jaki jest rozkład czasu publikacji?</a></div><div class=\"lev3 toc-item\"><a href=\"#Jakiej-długości-są-teksty?\" data-toc-modified-id=\"Jakiej-długości-są-teksty?-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Jakiej długości są teksty?</a></div><div class=\"lev3 toc-item\"><a href=\"#Jakie-słowa-występują-najczęściej?\" data-toc-modified-id=\"Jakie-słowa-występują-najczęściej?-134\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Jakie słowa występują najczęściej?</a></div><div class=\"lev2 toc-item\"><a href=\"#Tekst-jako-wektor\" data-toc-modified-id=\"Tekst-jako-wektor-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Tekst jako wektor</a></div><div class=\"lev3 toc-item\"><a href=\"#Bag-of-words\" data-toc-modified-id=\"Bag-of-words-141\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Bag of words</a></div><div class=\"lev3 toc-item\"><a href=\"#Oczyszczanie-tekstu\" data-toc-modified-id=\"Oczyszczanie-tekstu-142\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Oczyszczanie tekstu</a></div><div class=\"lev4 toc-item\"><a href=\"#Tokenizacja,-stopwords,-częstość-wystąpień\" data-toc-modified-id=\"Tokenizacja,-stopwords,-częstość-wystąpień-1421\"><span class=\"toc-item-num\">1.4.2.1&nbsp;&nbsp;</span>Tokenizacja, stopwords, częstość wystąpień</a></div><div class=\"lev4 toc-item\"><a href=\"#Lemmatyzacja\" data-toc-modified-id=\"Lemmatyzacja-1422\"><span class=\"toc-item-num\">1.4.2.2&nbsp;&nbsp;</span>Lemmatyzacja</a></div><div class=\"lev4 toc-item\"><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1423\"><span class=\"toc-item-num\">1.4.2.3&nbsp;&nbsp;</span>Ćwiczenie</a></div><div class=\"lev2 toc-item\"><a href=\"#Wybieranie-słów-kluczowych\" data-toc-modified-id=\"Wybieranie-słów-kluczowych-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Wybieranie słów kluczowych</a></div><div class=\"lev3 toc-item\"><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>TF-IDF</a></div><div class=\"lev3 toc-item\"><a href=\"#Dodatkowe-materiały---dla-zainteresowanych\" data-toc-modified-id=\"Dodatkowe-materiały---dla-zainteresowanych-152\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Dodatkowe materiały - dla zainteresowanych</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob5ZCgEJKB-g"
   },
   "source": [
    "# Przetwarzanie tekstu - przygotowanie i analiza eksploracyjna\n",
    " W tej części warsztatów dowiesz się:\n",
    " - Jak przygotować tekst do analizy? - oczyszczanie, tokenizacja\n",
    " - Jak zamienić tekst na liczby? - podstawowe metody reprezentacji tekstu w postaci numerycznej (bag of words, TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJICKCLFKB-i"
   },
   "source": [
    "## Importy, czyli co będzie potrzebne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-17T21:44:36.075806Z",
     "start_time": "2018-11-17T21:44:36.054804Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1880,
     "status": "ok",
     "timestamp": 1536043463968,
     "user": {
      "displayName": "Joanna Misztal-Radecka",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111446858099756945650"
     },
     "user_tz": -120
    },
    "id": "J75NQ-uLKB-j",
    "outputId": "6dd9ac91-8e57-4b94-bcdc-5a93b4fe344e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jmradecka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jmradecka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# podstawowe operacje na danych\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# wizualizacja\n",
    "from matplotlib import pyplot as plt\n",
    "import wordcloud\n",
    "\n",
    "# przetwarzanie tekstu, preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# przetwarzanie danych\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SBjq93IKB-o"
   },
   "source": [
    "## Słowniczek\n",
    "- korpus (*corpus*) - zbiór tekstów\n",
    "- słownik (*dictionary*) - (indeksowana) lista słów w korpusie\n",
    "- TF-IDF - Term Frequency Inverse Document Frequency\n",
    "- stopwords - mało istotne słowa, które mogą zostać odfiltrowane (np. spójniki, zaimki itd.)\n",
    "- tokenizacja (*tokenization*) - podział tekstu na tokeny (słowa, ciągi znaków o zdefiniowanym znaczeniu)\n",
    "- lemmatyzacja (*lemmatization*) - sprowadzanie słów do form podstawowej (analiza morfologiczna) Przykład: *studies -> study*\n",
    "- stemming - sprowadzenie słów do formy podstawowej (zazwyczaj przez odcięcie pre-/sufiksów). Przykład: *studies->studi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZeW2vDvKB-q"
   },
   "source": [
    "## Analiza eksploracyjna\n",
    "\n",
    "Do analizy użyjemy materiałów ze zbioru danych \"All the news\" z Kaggle'a pochodzących z różnych serwisów internetowych.\n",
    "\n",
    "https://www.kaggle.com/snapcrack/all-the-news/downloads/articles1.csv/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Czytanie danych - artykułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:28:17.126198Z",
     "start_time": "2018-11-01T11:28:13.348820Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22781,
     "status": "ok",
     "timestamp": 1536043488397,
     "user": {
      "displayName": "Joanna Misztal-Radecka",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111446858099756945650"
     },
     "user_tz": -120
    },
    "id": "Gqbwr1VVKB-r",
    "outputId": "ef53241c-3c27-4441-bae6-1c3102350bed"
   },
   "outputs": [],
   "source": [
    "articles = pd.read_csv('articles1.csv.zip', compression='zip', index_col='id')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skąd pochodzą teksty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:29:31.503635Z",
     "start_time": "2018-11-01T11:29:31.246609Z"
    }
   },
   "outputs": [],
   "source": [
    "articles.groupby('publication').count().title.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaki jest rozkład czasu publikacji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:45:52.661741Z",
     "start_time": "2018-11-01T11:45:51.336608Z"
    }
   },
   "outputs": [],
   "source": [
    "articles.groupby('year').count().title.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:46:27.358210Z",
     "start_time": "2018-11-01T11:46:27.135188Z"
    }
   },
   "outputs": [],
   "source": [
    "articles.groupby('month').count().title.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:08:06.569082Z",
     "start_time": "2018-11-01T13:08:06.245050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1536043587425,
     "user": {
      "displayName": "Joanna Misztal-Radecka",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111446858099756945650"
     },
     "user_tz": -120
    },
    "id": "IfTeINznKB-t",
    "outputId": "c822d3de-1224-4623-ecb9-aea7004cfc8b"
   },
   "outputs": [],
   "source": [
    "articles.groupby(['year', 'publication']).count().reset_index().pivot(columns='publication', index='year', values='title').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jakiej długości są teksty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:32:13.657848Z",
     "start_time": "2018-11-01T11:32:13.556838Z"
    }
   },
   "outputs": [],
   "source": [
    "articles.content.apply(lambda x: len(x)).describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:02:58.206285Z",
     "start_time": "2018-11-01T12:02:58.125277Z"
    }
   },
   "outputs": [],
   "source": [
    "articles.title.apply(lambda x: len(x)).describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jakie słowa występują najczęściej?\n",
    "\n",
    "Tutorial o wordcloud https://www.datacamp.com/community/tutorials/wordcloud-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:51:02.835719Z",
     "start_time": "2018-11-01T12:50:54.435879Z"
    }
   },
   "outputs": [],
   "source": [
    "wc = wordcloud.WordCloud(background_color=\"white\")\\\n",
    "                        .generate(' '.join(articles.sample(2000).content.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:52:08.377272Z",
     "start_time": "2018-11-01T12:52:08.146249Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCtwZ_R0KB-w"
   },
   "source": [
    "## Tekst jako wektor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23HFB560KB-x"
   },
   "source": [
    "### Bag of words\n",
    "\n",
    "Najprostszym sposobem numerycznej reprezentacji tekstu jest zapis do postaci wektora, gdzie każdy element odpowiada liczbie wystąpień słowa o danym id ze słownika w tekście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:33:30.746557Z",
     "start_time": "2018-11-01T11:33:02.596742Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-3dy6FLXKB-y"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(articles.content)\n",
    "print(\"Number of words in vocabulary:\")\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LucKebHKB-1"
   },
   "source": [
    "Słownik: wyrazy z przypisanym id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:33:36.754157Z",
     "start_time": "2018-11-01T11:33:36.697152Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kcytLgjhKB-2"
   },
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6fWkbHuKB-5"
   },
   "source": [
    "Przykład reprezentacji tekstu z korpusu\n",
    "\n",
    "Uwaga: w takiej reprezentacji wektor tekstu jest bardzo rzadki - zazwyczaj tylko kilka(dziesiąt/set) elementów ma dodatnie wartości, pozostałe są zerami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:34:43.908872Z",
     "start_time": "2018-11-01T11:34:43.643846Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9S6t8a_gKB-6"
   },
   "outputs": [],
   "source": [
    "test_text = articles.content.iloc[0]\n",
    "print('Text: ')\n",
    "print(test_text)\n",
    "test_vector = vectorizer.transform([test_text])\n",
    "print('BoW representation:')\n",
    "print(list(test_vector.toarray()[0]))\n",
    "print(\"Non-zero elements:\")\n",
    "print(test_vector.nonzero()[1])\n",
    "print(\"Words count:\")\n",
    "print(test_vector.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASwFt_7kKB_F"
   },
   "source": [
    "### Oczyszczanie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpyFWWLNKB_G"
   },
   "source": [
    "#### Tokenizacja, stopwords, częstość wystąpień\n",
    "\n",
    "W słowniku występuje wiele słów, które są mało istotne (występują bardzo często) lub bardzo rzadkie (np. błędnie zapisane). Przed rozpoczęciem przetwarzania warto przeprowadzić kroki takie jak:\n",
    "\n",
    "- usuwanie stopwords ze zdefiniowanej listy \n",
    "- tokenizacja  po wyrażeniu regularnym\n",
    "- filtrowanie po częstości wystąpień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:06:09.423405Z",
     "start_time": "2018-11-01T12:06:09.178380Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uC4Y7WNZKB_H"
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxb9itiCKB_L"
   },
   "source": [
    "Stopwords dla języka angielskiego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:04:25.655029Z",
     "start_time": "2018-11-01T12:04:25.605024Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IpresL0CKB_M"
   },
   "outputs": [],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EonQSjqKB_O"
   },
   "source": [
    "Usuwamy słowa zdefiniowane jako \"stopwords\", krótsze niż 3 znaki i składające się ze znaków innych niż litery alfabetu.\n",
    "Dodajemy też ograniczenie na częstość występowania słów - zostawiamy tylko, które występują w przynajmniej 10 i nie więcej niż połowie wszystkich dokumentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:11:56.545113Z",
     "start_time": "2018-11-01T12:11:34.689928Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GrpKSzCoKB_P"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-zA-Z]{3,}', max_df=0.5, min_df=10)\n",
    "vectorizer.fit(articles.content)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYoopgh3KB_W"
   },
   "source": [
    "#### Lemmatyzacja\n",
    "\n",
    "Do niektórych zastosowań przydatne jest sprowadzenie słów do formy podstawowej - lemmatyzacja (szukanie formy leksykalnej) lub stemming (obcięcie końcówek/przedrostków). Te podejścia nie zawsze dają takie same wyniki - zazwyczaj lemmatyzacja jest dokładniejsza, ale wymaga więcej czasu i pamięci (słownik)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gV_wQcqLkJY5"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = 'studies'\n",
    "stemma = stemmer.stem(word)\n",
    "lemma = lemmatizer.lemmatize(word)\n",
    "print(\"Word: {}, stemma: {}, lemma: {}\".format(word, stemma, lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8104HiDElCSA"
   },
   "source": [
    "Definiujemy funkcję do oczyszczania tekstu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:19:39.586413Z",
     "start_time": "2018-11-01T12:19:39.568411Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5cqEYMWWKB_X"
   },
   "outputs": [],
   "source": [
    "def preprocess_tokens(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.tokenize.regexp_tokenize(text, '[a-zA-Z]{3,}')\n",
    "    return [lemmatizer.lemmatize(word).lower() for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:21:53.428796Z",
     "start_time": "2018-11-01T12:19:39.754430Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UDp_jFCkKB_a"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', tokenizer=preprocess_tokens, max_df=0.5, min_df=10)\n",
    "vectorizer.fit(articles.content)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aEzUdGQKB_c"
   },
   "source": [
    "#### Ćwiczenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml68GQp_KB_d"
   },
   "source": [
    "Zmodyfikuj powyższy kod tak, żeby zostawić słowa kluczowe o długości przynajmniej 5 znaków, które występują w co najmniej 3 i co najwyżej 10% dokumentów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZN-jHbSKB-9"
   },
   "source": [
    "## Wybieranie słów kluczowych\n",
    "\n",
    "Przy reprezentacji tekstu przez zliczanie słów nie wiemy, które słowa są najbardziej charakterystyczne dla danego tekstu.\n",
    "\n",
    "Najbardziej interesujące są zwykle słowa, które występują często w danym tekście, a rzadko w pozostałych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fKd47Z1KB-_"
   },
   "source": [
    "### TF-IDF\n",
    "*Term Frequency Inverse Document Frequency* - algorytm obliczania wag dla słów proporcjonalnie do ich częstości występowania w danym teście i odwrotnie proporcjonalnie do ich częstości w całym korpusie, zgodnie ze wzorem:\n",
    "\n",
    "$tfidf_{t,d} = tf_{t,d} \\cdot idf_{t,d}$\n",
    "\n",
    "Im wyższa waga, tym bardziej charakterystyczne jest dane słowo dla danego dokumentu.\n",
    "\n",
    "Opis algorytmu w dokumentacji scikit-learn: http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:48:52.135650Z",
     "start_time": "2018-11-01T12:48:52.125649Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DVHsnvi2KB-_"
   },
   "outputs": [],
   "source": [
    "def get_top_terms(tfidf, document, top_n=10):\n",
    "    print(document[:100])\n",
    "    features = tfidf.get_feature_names()\n",
    "    terms_vec = tfidf.transform([document]).toarray()[0]\n",
    "    return [features[i] for i in np.argsort(terms_vec)[::-1][:top_n] if terms_vec[i]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T12:24:05.805032Z",
     "start_time": "2018-11-01T12:21:53.440797Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "azDnAQ5bKB_D"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', tokenizer=preprocess_tokens, max_df=0.5, min_df=10)\n",
    "tfidf.fit(articles.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T18:44:39.678648Z",
     "start_time": "2018-11-08T18:44:39.516632Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hVFYnx6KKB_e"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(get_top_terms(tfidf, articles.content.iloc[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YADX0EopDts"
   },
   "source": [
    "### Dodatkowe materiały - dla zainteresowanych\n",
    "\n",
    "* SpaCy - biblioteka do NLP ze wsparciem dla wielu języków (bardziej nastawiona na użycie produkcyne niż nltk) \n",
    "https://spacy.io\n",
    "* Opis materiałów dot. NLP dla języka polskiego http://clip.ipipan.waw.pl/LRT?action=show&redirect=lrt\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP workshop part 1 - preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "299px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
